version: "3.8"

services:
  # Kafka Broker (Apache Kafka con KRaft - sin Zookeeper)
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_NETWORK_THREADS: 3
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    networks:
      - uptimer-network
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9092 || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 40s

  # Producer - Monitor de la aplicación
  producer:
    build:
      context: .
      dockerfile: Dockerfile.producer
    container_name: uptimer-producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - API_URL=http://100.111.193.44:8001/health/
    networks:
      - uptimer-network
    restart: unless-stopped

  # Spark Processor - Procesamiento de streams
  spark-processor:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: uptimer-spark
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./datalake:/app/datalake
    networks:
      - uptimer-network
    restart: unless-stopped

  # Dashboard Reader - Visualización de métricas
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.dashboard
    container_name: uptimer-dashboard
    depends_on:
      - spark-processor
    volumes:
      - ./datalake:/app/datalake:ro
    networks:
      - uptimer-network
    restart: unless-stopped
    stdin_open: true
    tty: true

networks:
  uptimer-network:
    driver: bridge

volumes:
  datalake:
